{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce60f6db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/soroosh/projects/general_env/lib/python3.8/site-packages/pytorch_lightning/metrics/__init__.py:43: LightningDeprecationWarning: `pytorch_lightning.metrics.*` module has been renamed to `torchmetrics.*` and split off to its own package (https://github.com/PyTorchLightning/metrics) since v1.3 and will be removed in v1.5\n",
      "  rank_zero_deprecation(\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "from deepmusic import MusicRepr, Constants\n",
    "from importlib import reload\n",
    "\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, LearningRateMonitor\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e3c570",
   "metadata": {},
   "source": [
    "## data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "00ba9bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "const = Constants(unit=4, num_tempo_bins=20, num_velocity_bins=20)\n",
    "train_files = pickle.load(open('train_files.pkl', 'rb'))\n",
    "test_files = pickle.load(open('test_files.pkl', 'rb'))\n",
    "val_files = pickle.load(open('val_files.pkl', 'rb'))\n",
    "\n",
    "data_config = {\n",
    "    'data_dir' : '/home/soroosh/data/MIDI/LMD-Matched/lmd_processed/',\n",
    "    'const' : const,\n",
    "    'instruments' : ['piano', 'drums', 'guitar', 'bass', 'ensemble'],\n",
    "    'max_files' : 1200,\n",
    "    'window_len' : 5,\n",
    "    'max_len' : 640,\n",
    "    'pad_value' : 0,\n",
    "    'mask_prob' : 0.2,\n",
    "    'n_jobs' : 20\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "57d9d640",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c67cbb560162400989be7cdafd0562e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1053.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72ab9921c4ee4500b3adf56e9de6175e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=58.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b0dbaea9f164cbd8383d4a3a2518c56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=58.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import src.data.multi\n",
    "reload(src.data.multi)\n",
    "\n",
    "import src.data\n",
    "reload(src.data)\n",
    "\n",
    "from src.data import MultiTrackDataset, get_dataloaders\n",
    "\n",
    "train_dataset = MultiTrackDataset(**data_config, files=train_files)\n",
    "test_dataset = MultiTrackDataset(**data_config, files=test_files)\n",
    "val_dataset = MultiTrackDataset(**data_config, files=val_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3a0e9774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "piano 322\n",
      "drums 231\n",
      "guitar 86\n",
      "bass 190\n",
      "ensemble 312\n"
     ]
    }
   ],
   "source": [
    "sample = train_dataset[30]\n",
    "# for k in sample:\n",
    "#     print(k, len(sample[k]))\n",
    "for inst in sample:\n",
    "    print(inst, len(sample[inst]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6405707e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tl, vl = get_dataloaders(dataset, batch_size=2, n_jobs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3f7dab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "piano\n",
      "    X torch.Size([2, 244])\n",
      "    X_masked torch.Size([2, 244])\n",
      "    X_len torch.Size([2])\n",
      "    labels torch.Size([2, 244])\n",
      "    masked_labels torch.Size([2, 244])\n",
      "drums\n",
      "    X torch.Size([2, 518])\n",
      "    X_masked torch.Size([2, 518])\n",
      "    X_len torch.Size([2])\n",
      "    labels torch.Size([2, 518])\n",
      "    masked_labels torch.Size([2, 518])\n",
      "guitar\n",
      "    X torch.Size([2, 350])\n",
      "    X_masked torch.Size([2, 350])\n",
      "    X_len torch.Size([2])\n",
      "    labels torch.Size([2, 350])\n",
      "    masked_labels torch.Size([2, 350])\n",
      "bass\n",
      "    X torch.Size([2, 172])\n",
      "    X_masked torch.Size([2, 172])\n",
      "    X_len torch.Size([2])\n",
      "    labels torch.Size([2, 172])\n",
      "    masked_labels torch.Size([2, 172])\n",
      "ensemble\n",
      "    X torch.Size([2, 240])\n",
      "    X_masked torch.Size([2, 240])\n",
      "    X_len torch.Size([2])\n",
      "    labels torch.Size([2, 240])\n",
      "    masked_labels torch.Size([2, 240])\n"
     ]
    }
   ],
   "source": [
    "b = next(iter(vl))\n",
    "for inst in b:\n",
    "    print(inst)\n",
    "    for k in b[inst]:\n",
    "        print('   ', k, b[inst][k].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42f7319",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9727003b",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 256\n",
    "n_vocab = len(const.all_tokens)\n",
    "dropout = 0.1\n",
    "instruments = ['drums', 'ensemble', 'bass']\n",
    "memory_streams = ['piano', 'drums', 'guitar', 'ensemble', 'bass']\n",
    "\n",
    "model_config = {\n",
    "    'lr' : 1e-4,\n",
    "    'max_epochs' : 10,\n",
    "    'instruments' : instruments,\n",
    "    'tasks' : ['s2s'],\n",
    "    'embedding': {\n",
    "        'd_model' : d_model,\n",
    "        'n_vocab' : n_vocab,\n",
    "        'd_tok_emb' : 256,\n",
    "        'dropout' : dropout,\n",
    "        \n",
    "        'positional_embedding' : 'note',\n",
    "        'd_pos_emb' : 32,\n",
    "        'const' : const,\n",
    "        'max_bar' : 5,\n",
    "        'concat_pos' : True,\n",
    "#         'max_len' : 10000,\n",
    "        \n",
    "        'style_classes' : 0,\n",
    "        'd_style_emb' : 0\n",
    "    },\n",
    "    'encoder' : {\n",
    "        'd_model' : d_model,\n",
    "        'n_head' : 8,\n",
    "        'd_inner' : 512,\n",
    "        'dropout' : dropout,\n",
    "        'n_layer' : 4\n",
    "    },\n",
    "    'decoder' : {\n",
    "        'memory_streams' : memory_streams,\n",
    "        'd_model' : d_model,\n",
    "        'n_head' : 8,\n",
    "        'd_inner' : 512,\n",
    "        'dropout' : dropout,\n",
    "        'n_layer' : 4\n",
    "    },\n",
    "    'head' : {\n",
    "        'd_model' : d_model,\n",
    "        'n_vocab' : n_vocab\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a53dad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training tasks: s2s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9917373"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.models import EncoderMultiMemoryDecoderPerformer\n",
    "from src import Experiment\n",
    "\n",
    "model = EncoderMultiMemoryDecoderPerformer(model_config)\n",
    "\n",
    "# exp = Experiment(root_dir='exps/', name='exp_4')\n",
    "# model = EncoderMultiMemoryDecoderPerformer.load_from_checkpoint(exp.weights_path + 'last.ckpt', config=model_config)\n",
    "\n",
    "model.count_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8191b80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.0822, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits, loss = model(task='s2s', trg_inst='drums', inputs=b)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54e24fd",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41fd24f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'exps/exp_1/'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp = Experiment(\n",
    "    root_dir='exps/', \n",
    "    data_conf=data_config, \n",
    "    model_conf=model_config\n",
    ")\n",
    "exp.save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86aae671",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/soroosh/projects/general_env/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:396: LightningDeprecationWarning: Argument `period` in `ModelCheckpoint` is deprecated in v1.3 and will be removed in v1.5. Please use `every_n_val_epochs` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "logger = TensorBoardLogger(save_dir=exp.save_path, name='logs/')\n",
    "lr_logger = LearningRateMonitor(logging_interval='step')\n",
    "checkpoint = ModelCheckpoint(\n",
    "    dirpath=exp.weights_path, \n",
    "    filename='{epoch}-{val_loss:.2f}', \n",
    "    monitor='train_loss',\n",
    "    save_top_k=10, \n",
    "    period=1\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    benchmark=True, \n",
    "    gpus=1, \n",
    "    accumulate_grad_batches=16,\n",
    "    logger=logger, \n",
    "    max_epochs=model_config['max_epochs'],\n",
    "    callbacks=[checkpoint, lr_logger]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d0e841",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type                          | Params\n",
      "------------------------------------------------------------\n",
      "0 | criterion | CrossEntropyLoss              | 0     \n",
      "1 | embedding | RemiEmbedding                 | 164 K \n",
      "2 | encoder   | TransformerEncoder            | 2.1 M \n",
      "3 | decoder   | TransformerMultiMemoryDecoder | 7.4 M \n",
      "4 | heads     | ModuleDict                    | 270 K \n",
      "------------------------------------------------------------\n",
      "9.9 M     Trainable params\n",
      "0         Non-trainable params\n",
      "9.9 M     Total params\n",
      "39.669    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26b016e477064ca4a6f8c1b6bbb94e06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, tl, vl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f7a8976",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_checkpoint(f'{exp.weights_path}/last.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86955b2c",
   "metadata": {},
   "source": [
    "## generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "24d63277",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import Experiment\n",
    "\n",
    "exp = Experiment(root_dir='exps/', name='exp_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "336ad517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training tasks: s2s\n"
     ]
    }
   ],
   "source": [
    "from src.models import EncoderMultiMemoryDecoderPerformer\n",
    "\n",
    "\n",
    "gen_model = EncoderMultiMemoryDecoderPerformer.load_from_checkpoint(f\"{exp.weights_path}/last.ckpt\", config=exp.model_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2d4867",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_file(file):\n",
    "    seq = MusicRepr.from_file(data_config['data_dir'] + file, const=const).keep_instruments(['piano','drums', 'guitar', 'bass','ensemble'])\n",
    "    save_path = f'{exp.assets_path}{file[:-4]}/'\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    seq.to_midi(save_path + f'original.mid')\n",
    "    for inst in ['bass','drums','ensemble']:\n",
    "        generate_track(seq, inst, save_path, n_bar=50, start_idx=0)\n",
    "\n",
    "\n",
    "def generate_track(seq, trg_inst, save_path, n_bar=50, start_idx=0):\n",
    "    prompt = MusicRepr.concatenate(seq.get_bars()[start_idx:start_idx+n_bar]).remove_instruments([trg_inst])\n",
    "    print('generating',trg_inst, '...')\n",
    "    \n",
    "    res = gen_model.generate(trg_inst, seq=prompt, window=5, top_p=1., t=1.)\n",
    "    gen_seq = MusicRepr.from_indices(res, const=const)\n",
    "    \n",
    "    tracks = prompt.separate_tracks()\n",
    "    tracks[trg_inst] = gen_seq\n",
    "    final_seq = MusicRepr.merge_tracks(tracks)\n",
    "    \n",
    "    final_seq.to_midi(save_path + f'{trg_inst}_merge.mid')\n",
    "    gen_seq.to_midi(save_path + f'{trg_inst}_gen.mid')\n",
    "    prompt.to_midi(save_path + f'{trg_inst}_prompt.mid')\n",
    "\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.title(trg_inst)\n",
    "    plt.imshow(gen_seq.to_pianoroll(add_tempo_chord=False)[trg_inst])\n",
    "    plt.savefig(save_path + f'{trg_inst}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4a7a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in tqdm(files[-10:]):\n",
    "    evaluate_file(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e302484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !zip -r exps/exp_4/assets.zip exps/exp_4/assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964902bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
